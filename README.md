# üß† Teste T√©cnico: Agente de IA com RAG e LangChain

Este projeto √© a solu√ß√£o para o desafio t√©cnico de **Desenvolvedor de IA**, desenvolvendo um agente de IA completo capaz de realizar RAG (Retrieval-Augmented Generation) com documentos enviados pelo usu√°rio e conte√∫do extra√≠do da web.

A solu√ß√£o foi constru√≠da com foco em **modularidade**, **performance** (assincronismo) e **arquitetura limpa**, utilizando o framework Litestar e o ecossistema LangChain/LangGraph.

![Status](https://img.shields.io/badge/Status-Conclu√≠do-success)
![Docker](https://img.shields.io/badge/Docker-Compose-blue)
![Python](https://img.shields.io/badge/Python-3.13-yellow)
![Architecture](https://img.shields.io/badge/Architecture-Modular-orange)

---

## üé• Demo

![Chat Preview](assets/print-chat.png)

> **Assista ao v√≠deo demonstrativo:** [assets/2026-01-21-00-10-40.mp4](assets/2026-01-21-00-10-40.mp4)  
> _Nota: O v√≠deo n√£o possui √°udio, sendo apenas uma demonstra√ß√£o visual do sistema em funcionamento._

---

## üíª Requisitos de Sistema (Hardware)

‚ö†Ô∏è **Aten√ß√£o:** Como todo o processamento de IA (LLM + Embeddings + OCR) √© executado **localmente na CPU** (para garantir compatibilidade universal sem depender de GPU dedicada), o projeto exige recursos consider√°veis:

- **Mem√≥ria RAM**: M√≠nimo de **16GB**.
  - _Motivo:_ O Docker precisa alocar mem√≥ria para o modelo LLM, o modelo de embeddings, o banco de dados vetorial, e os servi√ßos de aplica√ß√£o simultaneamente.
- **CPU**: Processador moderno multi-core.
  - _Motivo:_ A infer√™ncia do modelo Qwen, o modelo de embeddings e o OCR do Tesseract s√£o tarefas intensivas de CPU.
- **Armazenamento**: ~10GB de espa√ßo livre (Imagens Docker + pesos dos modelos).

---

## üèõÔ∏è Arquitetura da API (Backend)

O cora√ß√£o do projeto √© a API desenvolvida em **Python 3.13** utilizando **Litestar**.

### Estrutura de Pastas Detalhada

```
api/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ app.py                  # Ponto de entrada (Entrypoint) e configura√ß√£o da App
‚îÇ   ‚îú‚îÄ‚îÄ logging_config.py       # Configura√ß√£o centralizada de Logs (Singleton)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ controllers/            # Camada de Apresenta√ß√£o (HTTP Handlers)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat_controller.py      # Gerencia SSE stream e uploads do chat
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scrape_controller.py    # Gerencia requisi√ß√µes de scraping
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ models/                 # Camada de Dados (Pydantic Models)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat_model.py           # Schemas de entrada/sa√≠da do chat
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scrape_model.py         # Schemas de requisi√ß√µes de scrape
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ services/               # Camada de Neg√≥cio (Core Logic)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat_service.py         # Orquestra o fluxo de mensagem -> agente -> resposta
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ingestion_service.py    # Processamento de arquivos (PDF, MarkItDown, OCR)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scraper_service.py      # L√≥gica de extra√ß√£o e limpeza da Web
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pgvector_service.py     # Abstra√ß√£o do Banco Vetorial (CRUD de embeddings)
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ agent/              # M√≥dulo do Agente Inteligente
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ agent.py            # Defini√ß√£o do grafo (LangGraph) e LLM
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ tools.py            # Ferramentas dispon√≠veis (Search Tool)
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ prompt.py           # Engenharia de Prompt e Regras de Sistema
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ Dockerfile                  # Build otimizado em multi-stage
‚îî‚îÄ‚îÄ pyproject.toml              # Gerenciamento de depend√™ncias (UV/Poetry standard)
```

### Componentes Chave

#### 1. Agente Inteligente (`src/services/agent/`)

Utilizamos **LangChain/LangGraph** para criar um agente do tipo **ReAct** (Reasoning + Acting).

- **Graph**: O agente n√£o √© uma corrente linear (Chain), mas um grafo de estados. Ele decide dinamicamente se precisa consultar uma ferramenta ou se pode responder diretamente.
- **Dynamic Prompting**: O _System Prompt_ n√£o √© est√°tico. A cada intera√ß√£o, injetamos a lista atualizada de arquivos dispon√≠veis na base de conhecimento, permitindo que o agente saiba exatamente o que pode consultar.
- **LLM**: Configurado para usar **Ollama** executando o modelo `qwen3:4b` com temperatura baixa (0.1) para reduzir alucina√ß√µes.

#### 2. Servi√ßo de Ingest√£o (`IngestionService`)

Respons√°vel por transformar dados brutos em conhecimento estruturado.

- **Pipeline de Processamento**:
  1.  Identifica o tipo MIME do arquivo.
  2.  Seleciona o extrator: `pdfplumber` (PDF), `pandas` (Excel/CSV), `markitdown` (Docs/Web) ou `pytesseract` (Imagens).
  3.  **OCR Fallback**: Se for uma imagem, aplica OCR para extrair o texto.
  4.  **Chunking**: Utiliza `RecursiveCharacterTextSplitter` para quebrar o texto em peda√ßos sem√¢nticos (chunks) de 1000 tokens com overlap.

#### 3. Banco Vetorial (`PgVectorService`)

Abstra√ß√£o sobre o **PostgreSQL + PGVector**.

- **Embeddings**: Utiliza o modelo `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2` (HuggingFace) para gerar vetores de alta qualidade em Portugu√™s.
- **Busca H√≠brida**: Permite busca sem√¢ntica filtrada por metadados (ex: buscar apenas dentro do arquivo "contrato.pdf").

---

## üõ†Ô∏è Stack Tecnol√≥gica

### Backend (API)

| Tecnologia         | Fun√ß√£o           | Motificativa                                                                      |
| ------------------ | ---------------- | --------------------------------------------------------------------------------- |
| **Litestar**       | Web Framework    | Inje√ß√£o de depend√™ncia robusta, valida√ß√£o autom√°tica de tipos, performance async. |
| **LangGraph**      | AI Orchestration | Permite fluxos c√≠clicos e controle de estado (memory) superior ao LangChain puro. |
| **LangChain**      | AI Utils         | Ferramentas de split de texto e abstra√ß√£o de modelos.                             |
| **Ollama**         | LLM Host         | Execu√ß√£o local de modelos open-source sem depender de API keys externas.          |
| **Pytesseract**    | OCR              | Extra√ß√£o de texto de imagens offline.                                             |
| **BeautifulSoup4** | Web Scraping     | Parsing eficiente de HTML est√°tico (Wikipedia).                                   |

### Infraestrutura

| Servi√ßo      | Container        | Descri√ß√£o                                                 |
| ------------ | ---------------- | --------------------------------------------------------- |
| **API**      | `impar-api`      | Backend Python. Exposto na porta 8000.                    |
| **Frontend** | `impar-frontend` | Nginx servindo Vue.js. Exposto na porta 80.               |
| **Database** | `impar-postgres` | PostgreSQL 16 image oficial `pgvector/pgvector:pg16`.     |
| **LLM**      | `impar-ollama`   | Ollama service. Gerencia o download e execu√ß√£o do modelo. |

---

## üöÄ Guia de Instala√ß√£o e Execu√ß√£o

### 1. Prepara√ß√£o

Certifique-se de ter o Docker Desktop instalado e rodando.

### 2. Execu√ß√£o (Docker Compose)

A aplica√ß√£o foi desenhada para ser "Zero Config" na primeira execu√ß√£o.

```bash
# Clone o projeto
git clone https://github.com/vitorflopes/impar-ai-test.git
cd impar-ai-test

# Inicie os servi√ßos (isso pode demorar na primeira vez)
docker-compose up --build
```

> **Nota do Build:** O build inicial ir√° baixar muitos arquivos. Tenha paci√™ncia.

### 3. Acessando

- **Chat**: http://localhost:80
- **Documenta√ß√£o API (Swagger UI)**: http://localhost:8000/schema/swagger

---

## ‚úÖ Cobertura dos Requisitos

### Obrigat√≥rios

- [x] **API Python (Litestar)**: Implementada.
- [x] **LangChain + LangGraph**: Implementados.
- [x] **PostgreSQL + PGVector**: Implementado e integrado.
- [x] **Ollama Local**: Integrado via Docker network.
- [x] **Ingest√£o de Arquivos**: PDF, CSV, Excel implementados.
- [x] **Scraping**: Endpoint `/scrape` funcional e integrado ao vector store.

### B√¥nus (Extras Entregues)

- [x] **Multiformato**: Suporte adicional a DOCX, PPTX, MD, JSON, HTML, TXT.
- [x] **OCR (Optical Character Recognition)**: Upload de imagens √© processado e indexado.
- [x] **Interface Rica**: Chat com suporte a Markdown, streaming e hist√≥rico da conversa.
- [x] **Logging**: Logs estruturados em json-like format para observabilidade.

---

**Desenvolvido por Vitor Lopes**
